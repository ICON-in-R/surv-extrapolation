{
  "hash": "9029f9c60bcc2b001cfc69ced309b37d",
  "result": {
    "markdown": "---\ntitle: \"AIC/BIC tests\"\nbibliography: references.bib\nformat:\n  html:\n    code-copy: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Background\n\nAkaike's Information Criterion (AIC) and the Bayesian Information Criterion (BIC) provide a useful statistical test of the relative fit of alternative parametric models, and they are usually available as outputs from statistical software. Further details on these are available from [@Collett2013]. Measures such as the negative 2 log likelihood are only suitable for comparing nested models, whereby one model is nested within another (for example, one model adds an additional covariate compared to another model). Different parametric models which use different probability distributions cannot be nested within one another. Thus the negative 2 log likelihood test is not suitable for assessing the fit of alternative parametric models. The AIC and BIC allow a comparison of models that do not have to be nested, including a term which penalises the use of unnecessary covariates (these are penalised more highly by the BIC). Generally, it is not necessary to include covariates in survival modelling in the context of an RCT as it would be expected that any important covariates would be balanced through the process of randomisation. However, some parametric models have more parameters than others, and the AIC and BIC take account of these -- for example an exponential model only has one parameter and so in comparative terms two parameter models such as the Weibull or Gompertz models are penalised. The AIC and BIC statistics therefore weigh up the improved fit of models with the potentially inefficient use of additional parameters, with the use of additional parameters penalised more highly by the BIC relative to the AIC.\n\nSuppose that we have a statistical model of some data. Let $k$ be the number of estimated parameters in the model. Let $\\hat{L}$ be the maximized value of the likelihood function for the model. Then the AIC value of the model is the following.\n\n\n$$\nAIC = 2k - 2 \\ln({\\hat{L}})\n$$\n\n\nGiven a set of candidate models for the data, the preferred model is the one with the minimum AIC value.\n\nThe BIC is formally defined as\n\n\n$$\nBIC = k \\ln(n) - 2 \\ln(\\widehat{L})\n$$\n\n\nwhere\n\n$\\hat{L}$ = the maximized value of the likelihood function of the model $M$, i.e. $\\hat{L} = p(x \\mid \\widehat{\\theta}, M)$, where $\\widehat{\\theta}$ are the parameter values that maximize the likelihood function; $x$ = the observed data; $n$ = the number of data points in $x$, the number of observations, or equivalently, the sample size; $k$ = the number of parameters estimated by the model. For example, in multiple linear regression, the estimated parameters are the intercept, the $q$ slope parameters, and the constant variance of the errors; thus, $k = q + 2$.\n\n:::{.callout-warning}\n## Relative values\n\nIC values only really make sense when compared between one another i.e relatively. The absolute value is not helpful and depends on the specifics of the model and data.\n:::\n\n\n## R example\n\nCox proportional hazard model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\n\ntest1 <- list(time=c(4,3,1,1,2,2,3), \n              status=c(1,1,1,0,1,1,0), \n              x=c(0,2,1,1,1,0,0), \n              sex=c(0,0,0,0,1,1,1)) \n# Fit a stratified model \nfit_ph <- coxph(Surv(time, status) ~ x + strata(sex), test1) \n\nAIC(fit_ph)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8.655313\n```\n:::\n\n```{.r .cell-code}\n##TODO: what this difference with AIC()?\nextractAIC(fit_ph)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.000000 8.655313\n```\n:::\n\n```{.r .cell-code}\nBIC(fit_ph)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8.264751\n```\n:::\n:::\n\n\n### Parametric model with `flexsurv`\n\nThe package `flexsurv` computes the AIC when it fits a model. This can be accessed by \\`.$AIC$ i.e.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(flexsurv)\n\nfitg <- flexsurvreg(formula = Surv(futime, fustat) ~ 1, data = ovarian, dist = \"gengamma\")\nfitg$AIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 199.8981\n```\n:::\n:::\n\n\nFor other information criteria statistics it is straightforward to calculate these using the `flexsurvreg` outpuu. For simplicity we can write a function to do them all at the same time, which we shall call `fitstats.flexsurvreg`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"fitstats.flexsurvreg() function\"}\n# helper function\n# from flexsurv github\n# https://github.com/chjackson/flexsurv-dev/issues/44\nfitstats.flexsurvreg <- function(x) {\n  ll <- x$loglik\n  aic <- x$AIC\n  k <- length(x$coefficients)\n  n <- sum(x$data$m[\"(weights)\"])\n  aicc <- aic + ((2 * k) * (k + 1) / (n - k - 1))\n  bic <- - 2 * ll + (k * log(n))\n  \n  data.frame(\n   Df = k,\n    \"n2ll\" = -2 * ll,\n    AIC = aic,\n    AICc = aicc,\n    BIC = bic)\n}\n```\n:::\n\n\nNow if we run this we obtain all of the statistics for the previous generalised gamma model fit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitstats.flexsurvreg(fitg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Df     n2ll      AIC    AICc      BIC\n1  3 193.8981 199.8981 200.989 203.6724\n```\n:::\n:::\n\n\n### Bayesian model with `survHE` package\n\nFirst let us fit an example model using `survHE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survHE)\n\ndata(bc)\n\n# Fits the same model using the 3 inference methods\nmle <- fit.models(formula = Surv(recyrs,censrec) ~ group,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n```\n:::\n\n\nNow, the print method for class `survHE` returns several model fitting summaries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(mle)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nModel fit for the Exponential model, obtained using Flexsurvreg \n(Maximum Likelihood Estimate). Running time: 0.020 seconds\n\n                 mean         se      L95%      U95%\nrate        0.0603838 0.00845542 0.0458911 0.0794534\ngroupMedium 0.8180219 0.17122084 0.4824352 1.1536086\ngroupPoor   1.5375232 0.16280169 1.2184378 1.8566087\n\nModel fitting summaries\nAkaike Information Criterion (AIC)....: 1668.212\nBayesian Information Criterion (BIC)..: 1681.805\n```\n:::\n:::\n\n\nIf we wished to access the values directly, perhaps to use in our own code, then we can use\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmle$model.fitting\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$aic\n[1] 1668.212\n\n$bic\n[1] 1681.805\n\n$dic\nNULL\n```\n:::\n:::\n\n\nFurther, if we were to fit several different models to compare the IC statistics, which is really the main point of doing it, then `survHE` also has some nice plotting functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmle_multi <- fit.models(formula = Surv(recyrs,censrec) ~ group,\n                  data = bc,\n                  distr = c(\"exp\", \"weibull\", \"gompertz\", \"lognormal\", \"loglogistic\"),\n                  method = \"mle\")\n\nmodel.fit.plot(mle_multi)\n```\n\n::: {.cell-output-display}\n![](AIC-BIC-tests_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmodel.fit.plot(mle_multi, type = \"BIC\")\n```\n\n::: {.cell-output-display}\n![](AIC-BIC-tests_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmodel.fit.plot(mle_multi, scale = \"relative\")\n```\n\n::: {.cell-output-display}\n![](AIC-BIC-tests_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "AIC-BIC-tests_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}