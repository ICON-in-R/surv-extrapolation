{
  "hash": "b0c628fc0772926e9765a61a545c1775",
  "result": {
    "markdown": "---\ntitle: \"Assessing model assumptions using log-cumulative hazard plots\"\n---\n\n\n## Background\n\nPrior to fitting a model based on an assumed parametric form for the hazard function, a preliminary study of the validity of this assumption should be carried-out.\n\nLet us compare the survivor function for the data with that from a chosen model. To do this we will transform the survivor function to produce a plot that should give a straight line if the assumed model is appropriate.\n\nFor the Weibull, twice taking logs of the survivor function with scale parameter $\\lambda$ and shape parameter $\\gamma$\n\n\n$$\nlog(-log S(t)) = log \\lambda + \\gamma log t\n$$\n\n\nA plot of $log(-log S(t))$ against $log(t)$ would give an approximately straight line if the Weibull assumption is reasonable. The plot could also be used to give a rough estimate of the parameters.\n\nSimilarly, for the log-logistic distribution\n\n\n$$\nlog S(t)/(1 - S(t)) = \\theta - \\kappa log t\n$$\n\n\nFor the log-normal distribution\n\n\n$$\n\\Phi^{-1} (1 - S(t)) = (log t - \\mu) / \\sigma\n$$ The slope and intercept of this line provide estimates of $\\sigma^{-1}$ and $-\\mu/\\sigma$, respectively.\n\n\nWe can also check the assumption made with using the Cox regression model of proportional hazards by inspecting the log-cumulative hazard plot.\n\n\n$$\nlog H_i(t) = \\beta x_i + log H_0(t)\n$$\n\n\nThe transformed curves for different values of the explanatory variables will be parallel if PH holds.\n\n## R examples\n\nThe package commonly used for survival analyses in R is the `survival` package (https://cran.r-project.org/web/packages/survival/vignettes/survival.pdf). We will begin by repeating an example from the `survival` help documentation.\n\nThis uses their `reliability` data. Firstly a little data manipulation is done before we plot the cumulative hazard plot against time using the in-built `survival` package plotting method with the `cumhaz=TRUE` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\n\ndata(\"reliability\", package = \"survival\")\n\nvdata <- with(valveSeat, data.frame(id = id, time2 = time, status = status))\nfirst <- !duplicated(vdata$id)\nvdata$time1 <- ifelse(first, 0, c(0, vdata$time[-nrow(vdata)]))\ndouble <- which(vdata$time1 == vdata$time2)\nvdata$time1[double] <- vdata$time1[double] - 0.01\nvdata$time2[double - 1] <- vdata$time1[double]\nvdata[1:7, c(\"id\", \"time1\", \"time2\", \"status\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   id  time1  time2 status\n1 251   0.00 761.00      0\n2 252   0.00 759.00      0\n3 327   0.00  98.00      1\n4 327  98.00 667.00      0\n5 328   0.00 326.00      1\n6 328 326.00 652.99      1\n7 328 652.99 653.00      1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- survfit(Surv(time1, time2, status) ~ 1, data = vdata, id = id)\nplot(fit, cumhaz = TRUE, xlab = \"Days\", ylab = \"Cumulative hazard\")\n```\n\n::: {.cell-output-display}\n![](assess-transformed-km_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nWe can plot the log-cumulative hazard against log-time by simply plotting the `survfit` output values directly by specifying the x and y data explicitly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(log(fit$time), log(fit$cumhaz), xlab = \"log-Days\", ylab = \"Log-cumulative hazard\", type = \"l\")\n```\n\n::: {.cell-output-display}\n![](assess-transformed-km_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nFor the following we will require the latest development version fo the `survHE` package. We can obtain this from GitHub with the following.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::install_github(\"giabaio/survHE\", ref = \"devel\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSkipping install of 'survHE' from a github remote, the SHA1 (24ef7d17) has not changed since last install.\n  Use `force = TRUE` to force installation\n```\n:::\n:::\n\n\nNow we can repeat the above analysis. By setting `distr = \"exp\"` the cumulative hazard plot is returned.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_exp <- survHE::fit.models(Surv(time1, time2, status) ~ 1,\n                              data = vdata, distr = \"exp\", method = \"mle\")\nsurvHE:::plot_transformed_km(fit_exp)\n```\n\n::: {.cell-output-display}\n![](assess-transformed-km_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nSetting `distr = \"weibull\"` then we get the log-cumulative hazard against log-time plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_wei <- survHE::fit.models(Surv(time1, time2, status) ~ 1,\n                              data = vdata, distr = \"weibull\", method = \"mle\")\nsurvHE:::plot_transformed_km(fit_wei)\n```\n\n::: {.cell-output-display}\n![](assess-transformed-km_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThe `plot_transformed_km` also provides plots for log-normal and log-logistic distribution assumptions with the corresponding transformation to the survival data.\n\nFurther, we could use the `flexsurv` package. This package contains lots of functions for a range of survival distributions.\n\nThe cumulative hazard can be plotted with the `flexsurv` plotting method with argument `type = \"cumhaz\"`. The Kaplan-Meier is also overlaid by the model fit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"flexsurv\")\n\nfs1 <- flexsurvreg(Surv(time1, time2, status) ~ 1, data = vdata, dist = \"exp\")\nplot(fs1, type = \"cumhaz\")\n```\n\n::: {.cell-output-display}\n![](assess-transformed-km_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfs2 <- flexsurvreg(Surv(time1, time2, status) ~ 1, data = vdata, dist = \"weibull\")\nplot(fs2, type = \"cumhaz\")\n```\n\n::: {.cell-output-display}\n![](assess-transformed-km_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n",
    "supporting": [
      "assess-transformed-km_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}