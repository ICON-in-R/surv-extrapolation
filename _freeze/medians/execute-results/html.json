{
  "hash": "1f711d98d6d964b497187d2d6390f83a",
  "result": {
    "markdown": "---\ntitle: \"Median survival time\"\nbibliography: references.bib\nformat:\n  html:\n    code-copy: true\neditor_options: \nchunk_output_type: console\n---\n\n\n## Background\n\nThe median survival time is the length of time from either the date of diagnosis or the start of treatment for a disease, such as cancer, that half of the patients in a group of patients diagnosed with the disease are still alive. In a clinical trial, measuring the median overall survival is one way to see how well a new treatment works. Also called median survival.\n\n::: callout-tip\nThe median is useful but it is the expected or mean survival time that is of particular interest for HTA.\n:::\n\n\n## R Examples\n\nIn this example we will see a comparison of survival probabilities at given landmark times as well as the comparison of observed (i.e. based on Kaplan-Meier) and predicted medians (using the respective formula to calculate the median for each distribution) based on fitted models for each of the 6 main distributions we consider.\n\nThe summary method for a `survHE` object from the `survHE` package returns mean survival times, including the median mean survival time (not be be confused with the mean median survival time!). For an exponential model fit with no covariates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survHE)\n\ndata(bc)\n\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n\nsummary(mle)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimated average survival time distribution* \n     mean        sd     2.5%   median    97.5%\n 4.526328 0.1118825 4.306837 4.531487 4.729995\n\n*Computed over the range: [0.02192-7.28493] using 1000 simulations.\nNB: Check that the survival curves tend to 0 over this range!\n```\n:::\n:::\n\n\nNote that this is calculated over a closed range and not the entire time line.\n\nWe can compare these parametric estimate with the median survival time from the Kaplan-Meier. This is available from the `survHE` output in `misc$km` and the equation\n\n\n$$\n\\min \\{t : \\hat{S}(t) < 0.5 \\}\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nt_med <- min(mle$misc$km$time[mle$misc$km$surv < 0.5])\nt_low <- min(mle$misc$km$time[mle$misc$km$lower < 0.5])\nt_upp <- min(mle$misc$km$time[mle$misc$km$upper < 0.5])\n\nt_med\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.950685\n```\n:::\n:::\n\n\nThere is clearly some repitition here so we can simplify as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_median <- function(S, sname) {\n  min(S[[\"time\"]][S[[sname]] < 0.5])\n}\n\nKM <- mle$misc$km\n\nsurv_median(KM, \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.950685\n```\n:::\n\n```{.r .cell-code}\nsurv_median(KM, \"lower\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.347945\n```\n:::\n\n```{.r .cell-code}\nsurv_median(KM, \"upper\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.561644\n```\n:::\n:::\n\n\nPlotting the Kaplan-Meier we can indicate these median times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvfit(Surv(recyrs, censrec) ~ 1, data = bc) |> \n  plot()\nabline(h = 0.5)\nabline(v = c(t_low, t_med, t_upp), lty = c(2,1,2))\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Direct estimates\n\nIf we denote the median with $t_{50}$ then to calculate the medians ourselves we can take the fitted coefficient value from the `fit.model` output and use an inverese of the survival function.\nIn the case of the exponential distribution this is\n\n\n$$\nt_{50} = -\\log (0.5)/\\lambda\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nrate <- mle$models$Exponential$coefficients\nexp(rate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1414765\n```\n:::\n\n```{.r .cell-code}\n# closed form\nmeantime <- -log(0.5)/exp(rate)\nmeantime\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.899379\n```\n:::\n:::\n\n\nThe log-logistic distribution has CDF\n\n\n$$\n\\frac{1}{(1 + (t/\\alpha)^{\\beta})^2}\n$$\n\n\nWhich leads to the median $t_{50} = \\alpha$, i.e. simply the shape parameter.\n\nSimilarly, the Gompertz distribution median is\n\n\n$$\n(1/b) \\log[(-1/\\eta) \\log(0.5) + 1]\n$$\n\n\nThe Weibull distribution median is\n\n\n$$\n\\lambda [- \\log(0.5)]^{1/k}\n$$\n\n\nThe log-normal distribution median is\n\n\n$$\n\\exp(\\mu)\n$$\n\n\n\nThe gamma distribution has no simple closed form formula for the median.\n\n\n### Simulation-based estimates\n\nNote that the parameter returned from `fit.model` is the log of the rate.\nMore generally, we can simulate (multiple) survival curves from the coefficient posterior and estimate the median for each of these.\nSo, sample from the posterior using `make.surv()` from the `survHE` package to obtain output for the single curve case as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_exp <- make.surv(mle)\n```\n:::\n\n\nThe sampled survival curves from `make.surv()` have slightly different names so let us redefine the median function and then extract the median times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_median <- function(S, sname) {\n  min(S[[\"t\"]][S[[sname]] < 0.5])\n}\n\nsurv <- surv_exp$S[[1]]\n\nsurv_median(surv, \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.893151\n```\n:::\n:::\n\n\nIt follows that we can do something similar for multiple simulations to obtain uncertainty bounds.\nRepeating the above but for 100 simulations,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim100 <- make.surv(mle, nsim = 100)\n```\n:::\n\n\ndirect estimates are\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtimes <- -log(0.5)/unlist(sim100$sim)\nrtimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 5.019496 4.977925 5.040677 5.030101 5.059512 5.067473 4.960593 5.432788\n  [9] 5.362015 4.941038 4.342166 4.660153 4.659891 4.812559 4.747552 5.004351\n [17] 4.793469 5.193077 5.201477 4.127722 4.662228 5.220832 4.426929 5.508646\n [25] 4.928799 5.323873 4.875220 5.128022 5.145417 5.303018 5.023271 4.622442\n [33] 5.012715 4.878703 5.583430 5.023745 5.006231 5.139021 4.954346 5.317653\n [41] 4.735700 5.140841 4.960132 5.247957 4.754201 4.992836 5.105168 5.007583\n [49] 4.382065 4.609377 4.810700 4.889177 4.977576 5.408317 5.105638 4.855109\n [57] 4.698811 4.605741 5.365495 4.903616 5.025636 4.526071 4.757562 5.132526\n [65] 4.568781 4.585415 5.113232 4.989097 4.930535 4.784125 4.507536 4.791772\n [73] 4.779063 4.585982 5.127042 4.845846 5.448710 4.905049 5.003483 4.670255\n [81] 5.147163 4.931005 5.047509 4.641959 4.623980 5.076626 4.958942 4.497899\n [89] 5.095520 4.398360 4.782857 4.735575 4.493488 4.565514 5.228715 4.870019\n [97] 5.045822 4.896110 4.498410 4.311245\n```\n:::\n:::\n\n\nand simulated estimates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv <- sim100$S[[1]]\n\nt_S <- surv_median(surv, \"S\")\nt_low <- surv_median(surv, \"low\")\nt_upp <- surv_median(surv, \"upp\")\n\nt_S\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.90137\n```\n:::\n:::\n\n\nThe plot with all samples of medians is,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mle) + \n  geom_vline(xintercept = rtimes, alpha = 0.1, col = \"darkgrey\", size = 2) +\n  geom_vline(xintercept = meantime) +\n  geom_vline(xintercept = t_low, linetype = 2) +\n  geom_vline(xintercept = t_upp, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n### Multiple distributions\n\nIn the same way as for a single distribution, we can extend the analysis for multiple distributions at the same time.\nWe show this for exponential and log-logistic distributions.\nFirst, fit the models and show the survival curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                   data = bc,\n                   dist = c(\"exp\", \"loglogistic\"),\n                   method = \"mle\")\n\nplot(fit2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThen, sample the survival curves and rearrange so that its straightforward to use the data in the same way as above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNSIM <- 100\nsim <- list()\nsim[[1]] <- make.surv(fit2, mod = 1, nsim = NSIM)\nsim[[2]] <- make.surv(fit2, mod = 2, nsim = NSIM)\n\nsim <- purrr::transpose(sim)\n```\n:::\n\n\nWe can then get the direct estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtimes <- list()\nrtimes[[1]] <- -log(0.5)/sim$sim[[1]][[1]][, \"rate\"]\nrtimes[[2]] <- sim$sim[[2]][[1]][, \"scale\"]\n\nrtimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n  [1] 4.904913 4.933991 5.004022 4.624629 5.302063 5.006858 4.812161 4.616890\n  [9] 4.894848 4.781428 5.191856 5.052430 4.830722 5.006891 5.233578 4.689772\n [17] 5.444921 4.821118 4.604853 5.218270 4.954131 5.133350 4.836315 5.803944\n [25] 4.934336 4.870179 4.884393 4.624474 4.650663 4.708646 5.005714 5.600479\n [33] 4.745149 5.830819 4.957067 4.774610 4.964351 5.271386 5.191127 4.846198\n [41] 5.160901 5.017303 4.986807 4.898055 4.702716 4.846492 4.957537 4.844318\n [49] 5.150092 4.530441 4.996794 5.203387 5.303392 5.043222 4.913962 5.478483\n [57] 5.388386 5.453340 4.622098 5.280943 4.601671 4.963340 4.806216 4.572630\n [65] 4.634410 5.125731 4.881193 4.860260 4.839871 4.745944 5.020383 4.996206\n [73] 4.738368 4.419159 5.700552 4.885201 4.595840 5.372853 5.713736 4.719554\n [81] 5.000018 4.599888 5.131084 5.035878 4.887494 5.072767 4.807541 5.218924\n [89] 4.678172 5.389019 4.639623 5.099674 4.636864 4.761363 5.287049 5.178298\n [97] 5.110573 4.610285 5.057809 5.213721\n\n[[2]]\n  [1] 4.277014 4.566690 4.401570 4.064939 4.591983 4.481928 4.763923 4.908186\n  [9] 4.219962 5.065799 4.704995 4.575944 4.461993 4.428678 4.553904 4.441652\n [17] 4.661240 4.359550 4.287016 4.323200 4.438166 4.697076 4.277220 4.381258\n [25] 4.370376 4.764005 4.597175 4.899001 4.503487 4.184343 4.359010 4.571090\n [33] 4.501373 4.718644 4.264050 4.653218 4.406219 4.261150 4.697457 4.259330\n [41] 4.265426 4.581331 4.684184 4.197287 4.178917 4.556705 5.002253 4.394140\n [49] 4.491093 4.787737 4.356263 4.946108 5.165638 4.290607 4.682076 4.284438\n [57] 4.445411 4.729226 4.539397 4.183968 4.490461 4.394591 4.667622 4.302596\n [65] 4.084217 4.822514 4.517111 4.529884 4.500607 4.657492 4.204231 4.161406\n [73] 4.250343 4.420957 4.924799 4.708339 4.258627 4.236294 4.858222 4.564900\n [81] 4.448974 4.748991 4.220136 4.543057 4.440298 4.472032 4.290453 4.133338\n [89] 4.536366 4.528996 4.601160 4.922568 4.548467 4.425991 4.453091 4.652182\n [97] 4.884402 4.529802 4.763379 4.551233\n```\n:::\n:::\n\n\nand the sampled estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulated estimates\nt_S <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"S\"))\nt_low <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"low\"))\nt_upp <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"upp\"))\n```\n:::\n\n\nPlotting the two sets of medians we can see the location and spread for both distributions together.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit2) + \n  geom_vline(xintercept = rtimes[[1]], alpha = 0.1, col = \"pink\", size = 2) +\n  geom_vline(xintercept = rtimes[[2]], alpha = 0.1, col = \"lightblue\", size = 2) +\n  geom_vline(xintercept = t_S[[1]]) +\n  geom_vline(xintercept = t_low[[1]], linetype = 2) +\n  geom_vline(xintercept = t_upp[[1]], linetype = 2) +\n  geom_vline(xintercept = t_S[[2]]) +\n  geom_vline(xintercept = t_low[[2]], linetype = 3) +\n  geom_vline(xintercept = t_upp[[2]], linetype = 3)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n### Multiple percentiles\n\nA general formula for the $p$th sample percentile of the survival time distribution is computed as\n\n\n$$\nt_p = \\frac{1}{2} \\left( \\min\\{t:1−\\hat{S}(t) ≥ p\\} + \\max\\{t:1−\\hat{S}(t) ≤ p\\} \\right)\n$$\n\n\nSo, analogous to the median only example above, let us fit an exponential distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n\nsurv <- make.surv(mle, nsim = NSIM)\n```\n:::\n\n\nWe can extend the `surv_median` function by creating a _function factory_ which we can use to create equivalent functions for different percentiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_percentile <- function(p) {\n  force(p)\n  function(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n}\n\nsurv_median <- surv_percentile(0.5)\nsurv_median(surv$S[[1]], \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.947945\n```\n:::\n:::\n\n\nNow we can automatically create functions for all the percentiles of interest by mapping over the vector of probabilities, which returns a list of functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprctile <- c(\"97.5\" = 0.975, \"75\" = 0.75, \"50\" = 0.5, \"25\" = 0.25, \"2.5\" = 0.025)\n\np_fns <- purrr::map(prctile, surv_percentile)\n\nhead(p_fns)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`97.5`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x000001d0a04b8bb0>\n<environment: 0x000001d0a077e9d0>\n\n$`75`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x000001d0a04b8bb0>\n<environment: 0x000001d0a04b2678>\n\n$`50`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x000001d0a04b8bb0>\n<environment: 0x000001d0a04b2950>\n\n$`25`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x000001d0a04b8bb0>\n<environment: 0x000001d0a04b2c60>\n\n$`2.5`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x000001d0a04b8bb0>\n<environment: 0x000001d0a04b2f38>\n```\n:::\n:::\n\n\nEquivalent to what we did with just the median function we can do the same with the list of percentile functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdat <- surv$S[[1]]\n\n# example for median i.e. 50% percentile\np_fns$`50`(simdat, \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.947945\n```\n:::\n\n```{.r .cell-code}\ne_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"S\")))\nupp_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"upp\")))\nlow_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"low\")))\n```\n:::\n\n\nWe can plot all of the percentile times with error bounds as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mle) + \n  geom_vline(xintercept = e_times) +\n  geom_vline(xintercept = upp_times, linetype = 2) +\n  geom_vline(xintercept = low_times, linetype = 2) +\n  annotate(\"text\", x = e_times + 0.5, y = 0.25, label = prctile)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n### Comparing between all distribution fits and Kaplan-Meier\n\nIn this section we bring together various things from previous sections.\nWe will do an analysis for all 6 main distributions at the same time and for several percentiles.\n\nFirst, we fit all of the models and then generate the sample of survival curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_names <- c(\"exponential\", \"weibull\", \"gompertz\", \"loglogistic\", \"lognormal\", \"gengamma\")\n\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = dist_names,\n                  method = \"mle\")\n\nsurv <- purrr::map(setNames(1:6, dist_names), ~ make.surv(mle, mod = .x, nsim = NSIM))\n```\n:::\n\n\nNow, for each distribution we calculate the survival times at each chosen percentile.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntimes <- list()\n\nfor (i in dist_names) {\n  simdat <- surv[[i]]$S[[1]]\n  times[[i]] <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"S\")))\n}\n```\n:::\n\n\nFinally, we can plot the results, including the Kaplan-Meier estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n\n## ggplot2 default colours\ncols <- hue_pal()(6)\nkm_dat <- mle$misc$km\n\nt_km <- purrr::map_dbl(prctile, ~min(km_dat$time[km_dat$surv < .x]))\n\nplot(mle) + \n  purrr::map(seq_along(times), ~ geom_vline(xintercept = times[[.x]], col = cols[.x])) +\n  geom_vline(xintercept = t_km, size = 1.5, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nWe haven't included the upper and lower bound here because the plot would be too busy but it is trivial to extend the code above to do this.\n\nLet us create a table of these percentile outputs too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- t(do.call(rbind, times))\ntab <- cbind(tab, Observed = t_km)\n\nknitr::kable(round(tab, 2))\n```\n\n::: {.cell-output-display}\n|     | exponential| weibull| gompertz| loglogistic| lognormal| gengamma| Observed|\n|:----|-----------:|-------:|--------:|-----------:|---------:|--------:|--------:|\n|97.5 |        0.18|    0.41|     0.27|        0.44|      0.52|     0.58|     0.56|\n|75   |        2.03|    2.34|     2.17|        2.19|      2.18|     2.03|     1.99|\n|50   |        4.89|    4.66|     4.80|        4.50|      4.60|     4.75|     4.95|\n|25   |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|      Inf|\n|2.5  |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|      Inf|\n:::\n:::\n\n\n\n### Survival probabilities at given times\n\nWe can flip the analysis around and instead obtain survival probabilities at user-defined time points.\n\nThe code looks veery similar to the percentile case above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_pt <- c(1,2,5)\n\nS_est <- list()\n\nfor (i in dist_names) {\n  simdat <- surv[[i]]$S[[1]]\n  S_est[[i]] <- purrr::map_dbl(t_pt, ~min(simdat$S[simdat$t < .x]))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkm_dat <- mle$misc$km\nt_km <- purrr::map_dbl(t_pt, ~min(km_dat$surv[km_dat$time < .x]))\n\nplot(mle) + \n  purrr::map(seq_along(S_est), ~ geom_hline(yintercept = S_est[[.x]], col = cols[.x])) +\n  geom_vline(xintercept = t_pt) +\n  geom_hline(yintercept = t_km, size = 1.5, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nLet us create a table of these survival probabilities as percentages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- t(do.call(rbind, S_est))\ntab <- cbind(time = t_pt, tab*100, Observed = t_km*100)\n\nknitr::kable(round(tab, 0))\n```\n\n::: {.cell-output-display}\n| time| exponential| weibull| gompertz| loglogistic| lognormal| gengamma| Observed|\n|----:|-----------:|-------:|--------:|-----------:|---------:|--------:|--------:|\n|    1|          87|      91|       88|          91|        92|       91|       92|\n|    2|          75|      79|       77|          78|        77|       75|       75|\n|    5|          49|      47|       48|          46|        47|       49|       49|\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"calc_medians() function\"}\n##TODO:\ncalc_medians <- function(fit, NSIM = 10) {\n  \n  dist_names <- fit$distns\n  ndist <- length(dist_names)\n  \n  surv <- purrr::map(setNames(1:ndist, dist_names),\n                     ~ make.surv(mle, mod = .x, nsim = NSIM))\n  \n  med_sim <- vector(length = ndist)\n  \n  for (i in dist_names) {\n    simdat <- surv[[i]]$S[[1]]\n    med_sim[i] <- surv_median(simdat, \"S\")\n  }\n  \n  median_fn <-\n    switch(fit$distn,\n           exp         = function(rate) -log(0.5)/exp(rate),\n           loglogistic = function(alpha) alpha,\n           gompertz    = function(b, eta) (1/b)*log((-1/eta)*log(0.5) + 1),\n           weibull     = function(lambda, k) lambda*(-log(0.5)^(1/k)),\n           lognormal   = function(mu) exp(mu)) \n  \n  med_direct <- do.call(median_fn, fit$sim)\n  \n  list(med_direct,\n       med_sim)\n}\n\nsurv_median <- function(S, sname) {\n  min(S[[\"t\"]][S[[sname]] < 0.5])\n}\n```\n:::\n",
    "supporting": [
      "medians_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}