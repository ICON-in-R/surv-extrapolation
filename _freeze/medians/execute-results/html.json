{
  "hash": "4d022cd41a42cbaf43f28b0a8b40d17b",
  "result": {
    "markdown": "---\ntitle: \"Median survival time\"\nbibliography: references.bib\nformat:\n  html:\n    code-copy: true\neditor_options: \nchunk_output_type: console\n---\n\n\n## Background\n\nThe median survival time is the length of time from either the date of diagnosis or the start of treatment for a disease, such as cancer, that half of the patients in a group of patients diagnosed with the disease are still alive. In a clinical trial, measuring the median overall survival is one way to see how well a new treatment works. Also called median survival.\n\n::: callout-tip\nThe median is useful but it is the expected or mean survival time that is of particular interest for HTA.\n:::\n\n## R Examples\n\nIn this example we will see a comparison of survival probabilities at given landmark times as well as the comparison of observed (i.e. based on Kaplan-Meier) and predicted medians (using the respective formula to calculate the median for each distribution) based on fitted models for each of the 6 main distributions we consider.\n\nThe summary method for a `survHE` object from the `survHE` package returns mean survival times, including the median mean survival time (not be be confused with the mean median survival time!). For an exponential model fit with no covariates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survHE)\n\ndata(bc)\n\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n\nsummary(mle)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimated average survival time distribution* \n mean sd 2.5% median 97.5%\n    0  0    0      0     0\n\n*Computed over the range: [0.02192-7.28493] using 1000 simulations.\nNB: Check that the survival curves tend to 0 over this range!\n```\n:::\n:::\n\n\nNote that this is calculated over a closed range and not the entire time line.\n\nWe can compare these parametric estimate with the median survival time from the Kaplan-Meier. This is available from the `survHE` output in `misc$km` and the equation\n\n\n$$\n\\min \\{t : \\hat{S}(t) < 0.5 \\}\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nt_med <- min(mle$misc$km$time[mle$misc$km$surv < 0.5])\nt_low <- min(mle$misc$km$time[mle$misc$km$lower < 0.5])\nt_upp <- min(mle$misc$km$time[mle$misc$km$upper < 0.5])\n\nt_med\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.950685\n```\n:::\n:::\n\n\nThere is clearly some repitition here so we can simplify as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_median <- function(S, sname) {\n  min(S[[\"time\"]][S[[sname]] < 0.5])\n}\n\nKM <- mle$misc$km\n\nsurv_median(KM, \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.950685\n```\n:::\n\n```{.r .cell-code}\nsurv_median(KM, \"lower\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.347945\n```\n:::\n\n```{.r .cell-code}\nsurv_median(KM, \"upper\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.561644\n```\n:::\n:::\n\n\nPlotting the Kaplan-Meier we can indicate these median times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvfit(Surv(recyrs, censrec) ~ 1, data = bc) |> \n  plot()\nabline(h = 0.5)\nabline(v = c(t_low, t_med, t_upp), lty = c(2,1,2))\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Direct estimates\n\nIf we denote the median with $t_{50}$ then to calculate the medians ourselves we can take the fitted coefficient value from the `fit.model` output and use an inverese of the survival function. In the case of the exponential distribution this is\n\n\n$$\nt_{50} = -\\log (0.5)/\\lambda\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nrate <- mle$models$Exponential$coefficients\nexp(rate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1414765\n```\n:::\n\n```{.r .cell-code}\n# closed form\nmeantime <- -log(0.5)/exp(rate)\nmeantime\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.899379\n```\n:::\n:::\n\n\nThe log-logistic distribution has CDF\n\n\n$$\n\\frac{1}{(1 + (t/\\alpha)^{\\beta})^2}\n$$\n\n\nWhich leads to the median $t_{50} = \\alpha$, i.e. simply the shape parameter.\n\nSimilarly, the Gompertz distribution median is\n\n\n$$\n(1/b) \\log[(-1/\\eta) \\log(0.5) + 1]\n$$\n\n\nThe Weibull distribution median is\n\n\n$$\n\\lambda [- \\log(0.5)]^{1/k}\n$$\n\n\nThe log-normal distribution median is\n\n\n$$\n\\exp(\\mu)\n$$\n\n\nThe gamma distribution has no simple closed form formula for the median.\n\n### Simulation-based estimates\n\nNote that the parameter returned from `fit.model` is the log of the rate. More generally, we can simulate (multiple) survival curves from the coefficient posterior and estimate the median for each of these. So, sample from the posterior using `make.surv()` from the `survHE` package to obtain output for the single curve case as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_exp <- make.surv(mle)\n```\n:::\n\n\nThe sampled survival curves from `make.surv()` have slightly different names so let us redefine the median function and then extract the median times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_median <- function(S, sname) {\n  min(S[[\"t\"]][S[[sname]] < 0.5])\n}\n\nsurv <- surv_exp$S[[1]]\n\nsurv_median(surv, \"S\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] Inf\n```\n:::\n:::\n\n\nIt follows that we can do something similar for multiple simulations to obtain uncertainty bounds. Repeating the above but for 100 simulations,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim100 <- make.surv(mle, nsim = 100)\n```\n:::\n\n\ndirect estimates are\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtimes <- -log(0.5)/unlist(sim100$sim)\nrtimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 5.129274 4.994966 5.143881 5.354052 4.122856 4.678172 4.636991 5.118422\n  [9] 4.797051 5.042906 4.734239 4.604857 5.175513 5.230992 4.882798 4.672267\n [17] 4.774438 4.569511 4.470436 4.557443 5.063112 4.608875 4.964719 5.499736\n [25] 4.715466 5.229862 4.999613 4.890220 4.914381 4.906810 5.050804 4.804258\n [33] 4.907729 5.002857 5.212119 5.219587 4.481277 4.574514 5.074015 4.966932\n [41] 4.668094 4.948967 5.061563 4.784166 5.048711 4.458354 5.227693 5.429019\n [49] 5.120158 4.989762 4.932618 5.333248 4.696408 4.967057 4.466571 5.487606\n [57] 4.998161 5.591646 5.264726 4.879369 4.805861 4.880135 5.017423 5.313824\n [65] 5.083576 5.123904 5.346759 4.884546 5.449213 4.774073 5.015380 5.133944\n [73] 4.407795 4.844915 4.878669 5.220372 4.979860 4.726083 4.809170 5.019526\n [81] 4.644216 4.937766 5.326748 4.888761 4.809222 4.958810 4.589322 4.520686\n [89] 4.866668 4.998618 5.270166 4.956875 5.127313 4.557834 4.634553 5.416319\n [97] 4.637491 4.237438 5.067876 5.459735\n```\n:::\n:::\n\n\nand simulated estimates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv <- sim100$S[[1]]\n\nt_S <- surv_median(surv, \"S\")\nt_low <- surv_median(surv, \"low\")\nt_upp <- surv_median(surv, \"upp\")\n\nt_S\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] Inf\n```\n:::\n:::\n\n\nThe plot with all samples of medians is,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mle) + \n  geom_vline(xintercept = rtimes, alpha = 0.1, col = \"darkgrey\", size = 2) +\n  geom_vline(xintercept = meantime) +\n  geom_vline(xintercept = t_low, linetype = 2) +\n  geom_vline(xintercept = t_upp, linetype = 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### Multiple distributions\n\nIn the same way as for a single distribution, we can extend the analysis for multiple distributions at the same time. We show this for exponential and log-logistic distributions. First, fit the models and show the survival curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                   data = bc,\n                   dist = c(\"exp\", \"loglogistic\"),\n                   method = \"mle\")\n\nplot(fit2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThen, sample the survival curves and rearrange so that its straightforward to use the data in the same way as above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNSIM <- 100\nsim <- list()\nsim[[1]] <- make.surv(fit2, mod = 1, nsim = NSIM)\nsim[[2]] <- make.surv(fit2, mod = 2, nsim = NSIM)\n\nsim <- purrr::transpose(sim)\n```\n:::\n\n\nWe can then get the direct estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtimes <- list()\nrtimes[[1]] <- -log(0.5)/sim$sim[[1]][[1]][, \"rate\"]\nrtimes[[2]] <- sim$sim[[2]][[1]][, \"scale\"]\n\nrtimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n  [1] 4.891236 5.558763 4.640760 4.955321 5.064032 4.952246 4.417258 4.785022\n  [9] 4.386729 5.174528 5.029145 5.103521 5.152045 4.913786 4.775232 4.745259\n [17] 4.921242 4.645849 4.648273 4.611302 4.596660 4.749946 5.000975 4.492578\n [25] 5.041510 5.037908 4.682468 4.941710 4.295228 5.419128 5.059493 5.461694\n [33] 5.067809 5.056597 4.723538 4.858205 5.189288 4.734738 4.644047 4.843307\n [41] 4.829866 4.534743 4.992454 4.865820 4.911094 4.890826 4.477248 4.928613\n [49] 4.710085 4.725032 5.070692 5.015997 4.919846 5.099190 4.665799 4.651995\n [57] 5.059758 4.107772 4.951071 5.553459 4.228464 4.758949 4.842218 4.608252\n [65] 5.199355 4.760746 5.160960 4.295892 4.690292 5.199554 4.795301 5.300827\n [73] 4.894303 5.097581 4.752782 4.628371 5.333848 5.036416 5.257309 4.609605\n [81] 5.184192 5.229711 5.316874 4.935175 4.630972 5.059328 5.080439 4.923191\n [89] 5.564449 4.840336 4.778244 4.910046 4.890228 5.803821 4.597359 5.034822\n [97] 5.004193 4.842067 5.046290 5.192478\n\n[[2]]\n  [1] 4.466570 4.619031 4.022234 4.828505 4.246242 4.124056 4.588208 5.056415\n  [9] 4.462401 4.442259 4.602219 4.712382 4.667207 4.667028 4.526850 4.390890\n [17] 4.310906 4.883069 4.271361 4.951216 4.589956 4.342607 4.330297 4.432282\n [25] 4.433938 4.811139 4.399874 4.423267 4.563278 4.640146 4.617160 4.117204\n [33] 4.585883 4.609707 4.733523 4.680524 4.623114 4.594910 4.666122 4.656637\n [41] 4.451875 4.420331 4.605745 4.649875 4.429742 4.609523 4.134343 5.113835\n [49] 4.424969 4.928719 4.327575 5.004125 4.246994 4.594632 4.691098 4.278484\n [57] 4.398825 4.207993 4.574355 4.226589 4.612187 4.598995 4.518066 4.618010\n [65] 4.509008 4.425050 4.831216 4.753106 4.285328 4.515222 4.576484 4.243922\n [73] 4.312133 4.326376 4.364893 4.205415 4.634487 4.517175 4.062072 5.084034\n [81] 4.835280 4.660257 4.401611 4.536356 4.603107 4.437586 4.663069 4.813495\n [89] 4.361790 4.823949 5.333890 4.583438 4.576911 4.384318 4.610598 4.511460\n [97] 4.486576 4.259209 4.164961 4.357421\n```\n:::\n:::\n\n\nand the sampled estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulated estimates\nt_S <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"S\"))\nt_low <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"low\"))\nt_upp <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"upp\"))\n```\n:::\n\n\nPlotting the two sets of medians we can see the location and spread for both distributions together.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit2) + \n  geom_vline(xintercept = rtimes[[1]], alpha = 0.1, col = \"pink\", size = 2) +\n  geom_vline(xintercept = rtimes[[2]], alpha = 0.1, col = \"lightblue\", size = 2) +\n  geom_vline(xintercept = t_S[[1]]) +\n  geom_vline(xintercept = t_low[[1]], linetype = 2) +\n  geom_vline(xintercept = t_upp[[1]], linetype = 2) +\n  geom_vline(xintercept = t_S[[2]]) +\n  geom_vline(xintercept = t_low[[2]], linetype = 3) +\n  geom_vline(xintercept = t_upp[[2]], linetype = 3)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n### Multiple percentiles\n\nA general formula for the $p$th sample percentile of the survival time distribution is computed as\n\n\n$$\nt_p = \\frac{1}{2} \\left( \\min\\{t:1−\\hat{S}(t) ≥ p\\} + \\max\\{t:1−\\hat{S}(t) ≤ p\\} \\right)\n$$\n\n\nSo, analogous to the median only example above, let us fit an exponential distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n\nsurv <- make.surv(mle, nsim = NSIM)\n```\n:::\n\n\nWe can extend the `surv_median` function by creating a *function factory* which we can use to create equivalent functions for different percentiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_percentile <- function(p) {\n  force(p)\n  function(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n}\n\nsurv_median <- surv_percentile(0.5)\nsurv_median(surv$S[[1]], \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] Inf\n```\n:::\n:::\n\n\nNow we can automatically create functions for all the percentiles of interest by mapping over the vector of probabilities, which returns a list of functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprctile <- c(\"97.5\" = 0.975, \"75\" = 0.75, \"50\" = 0.5, \"25\" = 0.25, \"2.5\" = 0.025)\n\np_fns <- purrr::map(prctile, surv_percentile)\n\nhead(p_fns)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`97.5`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000216baa60d38>\n<environment: 0x00000216bb4b3ab8>\n\n$`75`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000216baa60d38>\n<environment: 0x00000216baa63560>\n\n$`50`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000216baa60d38>\n<environment: 0x00000216baa63288>\n\n$`25`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000216baa60d38>\n<environment: 0x00000216baa62fb0>\n\n$`2.5`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000216baa60d38>\n<environment: 0x00000216baa62cd8>\n```\n:::\n:::\n\n\nEquivalent to what we did with just the median function we can do the same with the list of percentile functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdat <- surv$S[[1]]\n\n# example for median i.e. 50% percentile\np_fns$`50`(simdat, \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] Inf\n```\n:::\n\n```{.r .cell-code}\ne_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"S\")))\nupp_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"upp\")))\nlow_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"low\")))\n```\n:::\n\n\nWe can plot all of the percentile times with error bounds as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mle) + \n  geom_vline(xintercept = e_times) +\n  geom_vline(xintercept = upp_times, linetype = 2) +\n  geom_vline(xintercept = low_times, linetype = 2) +\n  annotate(\"text\", x = e_times + 0.5, y = 0.25, label = prctile)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n### Comparing between all distribution fits and Kaplan-Meier\n\nIn this section we bring together various things from previous sections. We will do an analysis for all 6 main distributions at the same time and for several percentiles.\n\nFirst, we fit all of the models and then generate the sample of survival curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_names <- c(\"exponential\", \"weibull\", \"gompertz\", \"loglogistic\", \"lognormal\", \"gengamma\")\n\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = dist_names,\n                  method = \"mle\")\n\nsurv <- purrr::map(setNames(1:6, dist_names), ~ make.surv(mle, mod = .x, nsim = NSIM))\n```\n:::\n\n\nNow, for each distribution we calculate the survival times at each chosen percentile.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntimes <- list()\n\nfor (i in dist_names) {\n  simdat <- surv[[i]]$S[[1]]\n  times[[i]] <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"S\")))\n}\n```\n:::\n\n\nFinally, we can plot the results, including the Kaplan-Meier estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n\n## ggplot2 default colours\ncols <- hue_pal()(6)\nkm_dat <- mle$misc$km\n\nt_km <- purrr::map_dbl(prctile, ~min(km_dat$time[km_dat$surv < .x]))\n\nplot(mle) + \n  purrr::map(seq_along(times), ~ geom_vline(xintercept = times[[.x]], col = cols[.x])) +\n  geom_vline(xintercept = t_km, size = 1.5, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nWe haven't included the upper and lower bound here because the plot would be too busy but it is trivial to extend the code above to do this.\n\nLet us create a table of these percentile outputs too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- t(do.call(rbind, times))\ntab <- cbind(tab, Observed = t_km)\n\nknitr::kable(round(tab, 2))\n```\n\n::: {.cell-output-display}\n|     | exponential| weibull| gompertz| loglogistic| lognormal| gengamma| Observed|\n|:----|-----------:|-------:|--------:|-----------:|---------:|--------:|--------:|\n|97.5 |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|     0.56|\n|75   |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|     1.99|\n|50   |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|     4.95|\n|25   |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|      Inf|\n|2.5  |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|      Inf|\n:::\n:::\n\n\n### Survival probabilities at given times\n\nWe can flip the analysis around and instead obtain survival probabilities at user-defined time points.\n\nThe code looks veery similar to the percentile case above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_pt <- c(1,2,5)\n\nS_est <- list()\n\nfor (i in dist_names) {\n  simdat <- surv[[i]]$S[[1]]\n  S_est[[i]] <- purrr::map_dbl(t_pt, ~min(simdat$S[simdat$t < .x]))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkm_dat <- mle$misc$km\nt_km <- purrr::map_dbl(t_pt, ~min(km_dat$surv[km_dat$time < .x]))\n\nplot(mle) + \n  purrr::map(seq_along(S_est), ~ geom_hline(yintercept = S_est[[.x]], col = cols[.x])) +\n  geom_vline(xintercept = t_pt) +\n  geom_hline(yintercept = t_km, size = 1.5, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nLet us create a table of these survival probabilities as percentages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- t(do.call(rbind, S_est))\ntab <- cbind(time = t_pt, tab*100, Observed = t_km*100)\n\nknitr::kable(round(tab, 0))\n```\n\n::: {.cell-output-display}\n| time| exponential| weibull| gompertz| loglogistic| lognormal| gengamma| Observed|\n|----:|-----------:|-------:|--------:|-----------:|---------:|--------:|--------:|\n|    1|         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|       92|\n|    2|         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|       75|\n|    5|         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|       49|\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"calc_medians() function\"}\n##TODO:\n## \ncalc_medians <- function(fit, NSIM = 10) {\n  \n  dist_names <- names(fit$models)\n  ndist <- length(dist_names)\n  \n  med_sim <- list()\n  med_direct <- list()\n  surv <- list()\n  \n  for (i in dist_names) {\n    surv[[i]] <- make.surv(fit, mod = which(i == dist_names), nsim = NSIM)\n    simdat <- surv[[i]]$S[[1]]\n    \n    med_sim[[i]] <- c(median = surv_median(simdat, \"S\"),\n                      upp = surv_median(simdat, \"upp\"),\n                      low = surv_median(simdat, \"low\"))\n    \n    params <- sample_params(fit$models[[i]])\n    \n    ##TODO: mean, upper and lower and/or all samples?\n    # median_fn <- fit$models[[i]]$dfns$q\n    # med_args <- c(p = 0.5, lower.tail = FALSE)\n    # med_direct[[i]] <- purrr::map(params, ~ do.call(median_fn, c(med_args, as.list(.x))))\n    med_direct[[i]] <- purrr::map_dbl(params, ~ do.call(median_fn(i), as.list(.x)))\n  }\n  \n  list(med_direct,\n       med_sim)\n}\n\nmedian_fn <- function(x) {\n  switch(x,\n         \"Exponential\"   = function(rate) -log(0.5)/rate,\n         \"log-Logistic\"  = function(shape, scale) scale,\n         \"Gompertz\"      = function(shape, rate) (1/rate)*log((-1/exp(shape))*log(0.5) + 1),\n         \"Weibull (AFT)\" = function(shape, scale) scale*(log(2)^(1/shape)),\n         \"log-Normal\"    = function(meanlog, sdlog) exp(meanlog),\n         \"Gen. Gamma\"    = function(...) NA)\n}\n\nsurv_median <- function(S, sname) {\n  min(S[[\"t\"]][S[[sname]] < 0.5])\n}\n\nsample_params <- function(fit, ...) {\n  UseMethod(\"sample_params\")\n}\n\nsample_params.flexsurvreg <- function(model, nsim = 10) {\n  sboot <- normboot.flexsurvreg(model, B = nsim)\n  asplit(sboot, 1)\n}\n\nsample_params.stan <- function() {\n  rstan::extract(model)\n}\n\ncalc_medians(mle)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n\nWarning in min(S[[\"t\"]][S[[sname]] < 0.5]): no non-missing arguments to min;\nreturning Inf\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[[1]]$Exponential\n [1] 4.966553 4.827020 4.883045 5.628640 5.035439 5.292257 5.089955 4.804941\n [9] 4.982657 4.810618\n\n[[1]]$`Weibull (AFT)`\n [1] 4.743420 4.493634 4.745278 4.337766 4.626728 4.657598 4.464190 4.717536\n [9] 4.582725 4.676070\n\n[[1]]$Gompertz\n [1] 4.046255 4.358841 4.227582 4.307995 4.373330 3.678017 3.759001 4.338441\n [9] 3.509706 3.523070\n\n[[1]]$`log-Logistic`\n [1] 5.013626 4.066543 4.580682 4.959065 4.212073 4.036718 4.555648 4.273214\n [9] 4.446469 4.491434\n\n[[1]]$`log-Normal`\n [1] 4.657814 4.132980 4.784933 5.107095 4.871923 4.441884 4.251263 4.747124\n [9] 4.518871 4.463943\n\n[[1]]$`Gen. Gamma`\n [1] NA NA NA NA NA NA NA NA NA NA\n\n\n[[2]]\n[[2]]$Exponential\nmedian    upp    low \n   Inf    Inf    Inf \n\n[[2]]$`Weibull (AFT)`\nmedian    upp    low \n   Inf    Inf    Inf \n\n[[2]]$Gompertz\nmedian    upp    low \n   Inf    Inf    Inf \n\n[[2]]$`log-Logistic`\nmedian    upp    low \n   Inf    Inf    Inf \n\n[[2]]$`log-Normal`\nmedian    upp    low \n   Inf    Inf    Inf \n\n[[2]]$`Gen. Gamma`\nmedian    upp    low \n   Inf    Inf    Inf \n```\n:::\n:::\n",
    "supporting": [
      "medians_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}