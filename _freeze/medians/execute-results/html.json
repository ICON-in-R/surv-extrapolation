{
  "hash": "1a979d99f6be8eb839fe5b648e50ab9b",
  "result": {
    "markdown": "---\ntitle: \"Median survival time\"\nbibliography: references.bib\nformat:\n  html:\n    code-copy: true\neditor_options: \nchunk_output_type: console\n---\n\n\n## Background\n\nThe median survival time is the length of time from either the date of diagnosis or the start of treatment for a disease, such as cancer, that half of the patients in a group of patients diagnosed with the disease are still alive. In a clinical trial, measuring the median overall survival is one way to see how well a new treatment works. Also called median survival.\n\n::: callout-tip\nThe median is useful but it is the expected or mean survival time that is of particular interest for HTA.\n:::\n\n\n## R Examples\n\nIn this example we will see a comparison of survival probabilities at given landmark times as well as the comparison of observed (i.e. based on Kaplan-Meier) and predicted medians (using the respective formula to calculate the median for each distribution) based on fitted models for each of the 6 main distributions we consider.\n\nThe summary method for a `survHE` object from the `survHE` package returns mean survival times, including the median mean survival time (not be be confused with the mean median survival time!). For an exponential model fit with no covariates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survHE)\n\ndata(bc)\n\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n\nsummary(mle)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimated average survival time distribution* \n     mean        sd    2.5%   median    97.5%\n 4.517346 0.1119987 4.27808 4.524495 4.725423\n\n*Computed over the range: [0.02192-7.28493] using 1000 simulations.\nNB: Check that the survival curves tend to 0 over this range!\n```\n:::\n:::\n\n\nNote that this is calculated over a closed range and not the entire time line.\n\nWe can compare these parametric estimate with the median survival time from the Kaplan-Meier. This is available from the `survHE` output in `misc$km` and the equation\n\n\n$$\n\\min \\{t : \\hat{S}(t) < 0.5 \\}\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nt_med <- min(mle$misc$km$time[mle$misc$km$surv < 0.5])\nt_low <- min(mle$misc$km$time[mle$misc$km$lower < 0.5])\nt_upp <- min(mle$misc$km$time[mle$misc$km$upper < 0.5])\n\nt_med\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.950685\n```\n:::\n:::\n\n\nThere is clearly some repitition here so we can simplify as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_median <- function(S, sname) {\n  min(S[[\"time\"]][S[[sname]] < 0.5])\n}\n\nKM <- mle$misc$km\n\nsurv_median(KM, \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.950685\n```\n:::\n\n```{.r .cell-code}\nsurv_median(KM, \"lower\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.347945\n```\n:::\n\n```{.r .cell-code}\nsurv_median(KM, \"upper\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.561644\n```\n:::\n:::\n\n\nPlotting the Kaplan-Meier we can indicate these median times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvfit(Surv(recyrs, censrec) ~ 1, data = bc) |> \n  plot()\nabline(h = 0.5)\nabline(v = c(t_low, t_med, t_upp), lty = c(2,1,2))\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Direct estimates\n\nIf we denote the median with $t_{50}$ then to calculate the medians ourselves we can take the fitted coefficient value from the `fit.model` output and use an inverese of the survival function.\nIn the case of the exponential distribution this is\n\n\n$$\nt_{50} = -\\log (0.5)/\\lambda\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nrate <- mle$models$Exponential$coefficients\nexp(rate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1414765\n```\n:::\n\n```{.r .cell-code}\n# closed form\nmeantime <- -log(0.5)/exp(rate)\nmeantime\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.899379\n```\n:::\n:::\n\n\nThe log-logistic distribution has CDF\n\n\n$$\n\\frac{1}{(1 + (t/\\alpha)^{\\beta})^2}\n$$\n\n\nWhich leads to the median $t_{50} = \\alpha$, i.e. simply the shape parameter.\n\nSimilarly, the Gompertz distribution median is\n\n\n$$\n(1/b) \\log[(-1/\\eta) \\log(0.5) + 1]\n$$\n\n\nThe Weibull distribution median is\n\n\n$$\n\\lambda [- \\log(0.5)]^{1/k}\n$$\n\n\nThe log-normal distribution median is\n\n\n$$\n\\exp(\\mu)\n$$\n\n\n\nThe gamma distribution has no simple closed form formula for the median.\n\n\n### Simulation-based estimates\n\nNote that the parameter returned from `fit.model` is the log of the rate.\nMore generally, we can simulate (multiple) survival curves from the coefficient posterior and estimate the median for each of these.\nSo, sample from the posterior using `make.surv()` from the `survHE` package to obtain output for the single curve case as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_exp <- make.surv(mle)\n```\n:::\n\n\nThe sampled survival curves from `make.surv()` have slightly different names so let us redefine the median function and then extract the median times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_median <- function(S, sname) {\n  min(S[[\"t\"]][S[[sname]] < 0.5])\n}\n\nsurv <- surv_exp$S[[1]]\n\nsurv_median(surv, \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.893151\n```\n:::\n:::\n\n\nIt follows that we can do something similar for multiple simulations to obtain uncertainty bounds.\nRepeating the above but for 100 simulations,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim100 <- make.surv(mle, nsim = 100)\n```\n:::\n\n\ndirect estimates are\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtimes <- -log(0.5)/unlist(sim100$sim)\nrtimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 5.030977 4.860997 5.252989 4.518656 4.799633 5.155153 5.058485 5.045317\n  [9] 4.674038 4.590355 5.082505 4.817995 5.004585 4.345927 5.234568 4.935574\n [17] 5.289443 4.937837 5.136835 5.397261 4.991506 4.687472 4.441882 5.297241\n [25] 4.979869 4.921964 5.291105 4.810240 4.932064 4.582963 4.832290 4.782677\n [33] 5.181210 4.676762 4.737412 4.864239 4.748428 4.943325 4.486343 5.128842\n [41] 5.043965 5.019482 5.262224 4.931228 5.050934 5.195667 5.225034 4.822411\n [49] 4.898454 4.915956 4.891791 4.525586 4.322594 4.706158 4.779160 4.541179\n [57] 4.455202 4.608087 4.958289 4.778545 4.941223 4.493003 5.070293 4.827053\n [65] 4.877539 4.613147 4.916051 5.140611 4.687538 4.914277 5.097975 4.678640\n [73] 4.889496 4.663478 4.903244 4.632844 4.085452 4.907163 4.561742 4.876387\n [81] 4.538998 5.104637 5.261416 4.834354 5.296088 4.794037 5.092592 4.717819\n [89] 5.300351 4.884407 4.896563 5.158070 4.990269 4.862905 4.982634 4.404314\n [97] 5.077803 5.287934 5.649222 5.019902\n```\n:::\n:::\n\n\nand simulated estimates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv <- sim100$S[[1]]\n\nt_S <- surv_median(surv, \"S\")\nt_low <- surv_median(surv, \"low\")\nt_upp <- surv_median(surv, \"upp\")\n\nt_S\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.893151\n```\n:::\n:::\n\n\nThe plot with all samples of medians is,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mle) + \n  geom_vline(xintercept = rtimes, alpha = 0.1, col = \"darkgrey\", size = 2) +\n  geom_vline(xintercept = meantime) +\n  geom_vline(xintercept = t_low, linetype = 2) +\n  geom_vline(xintercept = t_upp, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n### Multiple distributions\n\nIn the same way as for a single distribution, we can extend the analysis for multiple distributions at the same time.\nWe show this for exponential and log-logistic distributions.\nFirst, fit the models and show the survival curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                   data = bc,\n                   dist = c(\"exp\", \"loglogistic\"),\n                   method = \"mle\")\n\nplot(fit2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThen, sample the survival curves and rearrange so that its straightforward to use the data in the same way as above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNSIM <- 100\nsim <- list()\nsim[[1]] <- make.surv(fit2, mod = 1, nsim = NSIM)\nsim[[2]] <- make.surv(fit2, mod = 2, nsim = NSIM)\n\nsim <- purrr::transpose(sim)\n```\n:::\n\n\nWe can then get the direct estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtimes <- list()\nrtimes[[1]] <- -log(0.5)/sim$sim[[1]][[1]][, \"rate\"]\nrtimes[[2]] <- sim$sim[[2]][[1]][, \"scale\"]\n\nrtimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n  [1] 4.785691 4.773674 4.724659 4.169345 4.872511 4.646455 4.887068 4.809442\n  [9] 4.803092 5.132489 4.947968 4.806153 4.940416 4.788849 4.600579 4.797242\n [17] 4.752358 5.046295 5.056700 4.930276 4.718069 4.754700 4.811955 4.786615\n [25] 4.420308 5.279533 4.965886 5.085997 5.303584 4.781336 4.535886 4.459000\n [33] 4.940053 4.626905 4.994843 5.284709 4.620484 5.249167 5.610395 4.282181\n [41] 4.878309 5.084752 4.971148 4.679309 5.334013 4.789652 4.387141 4.536155\n [49] 5.284586 4.559396 4.392254 5.134116 5.050669 4.557677 5.055830 4.967826\n [57] 4.791461 4.893359 4.651476 4.781939 5.300166 5.219971 5.145551 5.045186\n [65] 5.158304 4.545387 5.596427 4.560900 4.899184 4.923309 4.868401 4.902518\n [73] 4.888902 4.854930 5.358622 5.437532 5.014616 4.865152 5.379231 4.667421\n [81] 4.729015 5.090545 5.113333 4.666649 5.291319 4.920715 4.700209 5.086914\n [89] 5.255839 4.593132 4.697289 4.906682 5.063687 4.543472 5.146893 5.216049\n [97] 5.370036 5.054706 4.988012 4.988741\n\n[[2]]\n  [1] 4.686934 4.443468 4.164848 4.787431 4.429112 4.619603 4.885367 4.461403\n  [9] 4.397005 4.052862 4.277117 4.482872 4.223199 4.580381 4.186790 4.486515\n [17] 4.485053 4.717372 4.424844 4.174030 4.793633 4.615457 4.260316 4.568796\n [25] 4.433402 4.688994 4.300801 4.525906 4.142817 4.379025 4.405320 4.362275\n [33] 4.609253 4.524031 4.599876 4.576962 4.979010 4.348849 4.237348 4.509658\n [41] 4.280489 5.057910 4.257423 4.463721 4.002849 4.462267 4.325352 5.008261\n [49] 4.711156 4.269269 4.347390 5.009185 4.171342 4.296398 4.027459 4.377073\n [57] 4.911544 4.454419 4.324823 4.923518 4.658023 4.643688 4.704392 4.524859\n [65] 4.387345 4.380771 4.570652 4.540388 4.562887 4.522572 4.751014 4.570938\n [73] 4.427822 4.723791 4.122711 4.555768 4.319784 4.709845 4.121744 4.712118\n [81] 4.779979 4.679062 4.238908 4.491942 4.599347 4.705663 4.280723 4.239860\n [89] 4.499630 4.472964 4.582056 4.567836 4.480996 4.642663 4.564446 4.807256\n [97] 4.065935 4.377016 5.196162 4.504275\n```\n:::\n:::\n\n\nand the sampled estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulated estimates\nt_S <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"S\"))\nt_low <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"low\"))\nt_upp <- purrr::map_dbl(sim$S, ~ surv_median(.x[[1]], \"upp\"))\n```\n:::\n\n\nPlotting the two sets of medians we can see the location and spread for both distributions together.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit2) + \n  geom_vline(xintercept = rtimes[[1]], alpha = 0.1, col = \"pink\", size = 2) +\n  geom_vline(xintercept = rtimes[[2]], alpha = 0.1, col = \"lightblue\", size = 2) +\n  geom_vline(xintercept = t_S[[1]]) +\n  geom_vline(xintercept = t_low[[1]], linetype = 2) +\n  geom_vline(xintercept = t_upp[[1]], linetype = 2) +\n  geom_vline(xintercept = t_S[[2]]) +\n  geom_vline(xintercept = t_low[[2]], linetype = 3) +\n  geom_vline(xintercept = t_upp[[2]], linetype = 3)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n### Multiple percentiles\n\nA general formula for the $p$th sample percentile of the survival time distribution is computed as\n\n\n$$\nt_p = \\frac{1}{2} \\left( \\min\\{t:1−\\hat{S}(t) ≥ p\\} + \\max\\{t:1−\\hat{S}(t) ≤ p\\} \\right)\n$$\n\n\nSo, analogous to the median only example above, let us fit an exponential distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = \"exp\",\n                  method = \"mle\")\n\nsurv <- make.surv(mle, nsim = NSIM)\n```\n:::\n\n\nWe can extend the `surv_median` function by creating a _function factory_ which we can use to create equivalent functions for different percentiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurv_percentile <- function(p) {\n  force(p)\n  function(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n}\n\nsurv_median <- surv_percentile(0.5)\nsurv_median(surv$S[[1]], \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.947945\n```\n:::\n:::\n\n\nNow we can automatically create functions for all the percentiles of interest by mapping over the vector of probabilities, which returns a list of functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprctile <- c(\"97.5\" = 0.975, \"75\" = 0.75, \"50\" = 0.5, \"25\" = 0.25, \"2.5\" = 0.025)\n\np_fns <- purrr::map(prctile, surv_percentile)\n\nhead(p_fns)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`97.5`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000252edba80c8>\n<environment: 0x00000252edf48270>\n\n$`75`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000252edba80c8>\n<environment: 0x00000252edb7e6f0>\n\n$`50`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000252edba80c8>\n<environment: 0x00000252edb7e9c8>\n\n$`25`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000252edba80c8>\n<environment: 0x00000252edb7eca0>\n\n$`2.5`\nfunction(S, sname)\n    min(S[[\"t\"]][S[[sname]] < p])\n<bytecode: 0x00000252edba80c8>\n<environment: 0x00000252edb7ef78>\n```\n:::\n:::\n\n\nEquivalent to what we did with just the median function we can do the same with the list of percentile functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdat <- surv$S[[1]]\n\n# example for median i.e. 50% percentile\np_fns$`50`(simdat, \"S\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.947945\n```\n:::\n\n```{.r .cell-code}\ne_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"S\")))\nupp_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"upp\")))\nlow_times <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"low\")))\n```\n:::\n\n\nWe can plot all of the percentile times with error bounds as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mle) + \n  geom_vline(xintercept = e_times) +\n  geom_vline(xintercept = upp_times, linetype = 2) +\n  geom_vline(xintercept = low_times, linetype = 2) +\n  annotate(\"text\", x = e_times + 0.5, y = 0.25, label = prctile)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n### Comparing between all distribution fits and Kaplan-Meier\n\nIn this section we bring together various things from previous sections.\nWe will do an analysis for all 6 main distributions at the same time and for several percentiles.\n\nFirst, we fit all of the models and then generate the sample of survival curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_names <- c(\"exponential\", \"weibull\", \"gompertz\", \"loglogistic\", \"lognormal\", \"gengamma\")\n\nmle <- fit.models(formula = Surv(recyrs, censrec) ~ 1,\n                  data = bc,\n                  distr = dist_names,\n                  method = \"mle\")\n\nsurv <- purrr::map(setNames(1:6, dist_names), ~ make.surv(mle, mod = .x, nsim = NSIM))\n```\n:::\n\n\nNow, for each distribution we calculate the survival times at each chosen percentile.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntimes <- list()\n\nfor (i in dist_names) {\n  simdat <- surv[[i]]$S[[1]]\n  times[[i]] <- purrr::map_dbl(p_fns, ~ do.call(.x, list(simdat, \"S\")))\n}\n```\n:::\n\n\nFinally, we can plot the results, including the Kaplan-Meier estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n\n## ggplot2 default colours\ncols <- hue_pal()(6)\nkm_dat <- mle$misc$km\n  \nt_km <- purrr::map_dbl(prctile, ~min(km_dat$time[km_dat$surv < .x]))\n\nplot(mle) + \n  purrr::map(seq_along(times), ~ geom_vline(xintercept = times[[.x]], col = cols[.x])) +\n  geom_vline(xintercept = t_km, size = 1.5, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nWe haven't included the upper and lower bound here because the plot would be too busy but it is trivial to extend the code above to do this.\n\nLet us create a table of these percentile outputs too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- t(do.call(rbind, times))\ntab <- cbind(tab, Observed = t_km)\n\nknitr::kable(round(tab, 2))\n```\n\n::: {.cell-output-display}\n|     | exponential| weibull| gompertz| loglogistic| lognormal| gengamma| Observed|\n|:----|-----------:|-------:|--------:|-----------:|---------:|--------:|--------:|\n|97.5 |        0.18|    0.41|     0.27|        0.44|      0.50|     0.58|     0.56|\n|75   |        2.03|    2.34|     2.18|        2.19|      2.17|     2.03|     1.99|\n|50   |        4.90|    4.66|     4.80|        4.50|      4.66|     4.81|     4.95|\n|25   |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|      Inf|\n|2.5  |         Inf|     Inf|      Inf|         Inf|       Inf|      Inf|      Inf|\n:::\n:::\n\n\n\n### Survival probabilities at given times\n\nWe can flip the analysis around and instead obtain survival probabilities at user-defined time points.\n\nThe code looks veery similar to the percentile case above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_pt <- c(1,2,5)\n\nS_est <- list()\n\nfor (i in dist_names) {\n  simdat <- surv[[i]]$S[[1]]\n  S_est[[i]] <- purrr::map_dbl(t_pt, ~min(simdat$S[simdat$t < .x]))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkm_dat <- mle$misc$km\nt_km <- purrr::map_dbl(t_pt, ~min(km_dat$surv[km_dat$time < .x]))\n\nplot(mle) + \n  purrr::map(seq_along(S_est), ~ geom_hline(yintercept = S_est[[.x]], col = cols[.x])) +\n  geom_vline(xintercept = t_pt) +\n  geom_hline(yintercept = t_km, size = 1.5, linetype = 2)\n```\n\n::: {.cell-output-display}\n![](medians_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nLet us create a table of these survival probabilities as percentages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- t(do.call(rbind, S_est))\ntab <- cbind(time = t_pt, tab*100, Observed = t_km*100)\n\nknitr::kable(round(tab, 0))\n```\n\n::: {.cell-output-display}\n| time| exponential| weibull| gompertz| loglogistic| lognormal| gengamma| Observed|\n|----:|-----------:|-------:|--------:|-----------:|---------:|--------:|--------:|\n|    1|          87|      91|       88|          91|        91|       91|       92|\n|    2|          75|      79|       77|          78|        77|       75|       75|\n|    5|          49|      47|       48|          46|        47|       49|       49|\n:::\n:::\n",
    "supporting": [
      "medians_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}