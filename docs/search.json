[
  {
    "objectID": "AIC-BIC-tests.html",
    "href": "AIC-BIC-tests.html",
    "title": "AIC-BIC tests",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assess-transformed-km.html",
    "href": "assess-transformed-km.html",
    "title": "Assessing model assumptions using log-cumulative hazard plots",
    "section": "",
    "text": "Prior to fitting a model based on an assumed parametric form for the hazard function, a preliminary study of the validity of this assumption should be carried-out.\nLet us compare the survivor function for the data with that from a chosen model. To do this we will transform the survivor function to produce a plot that should give a straight line if the assumed model is appropriate.\nFor the Weibull, twice taking logs of the survivor function with scale parameter \\(\\lambda\\) and shape parameter \\(\\gamma\\)\n\\[\nlog(-log S(t)) = log \\lambda + \\gamma log t\n\\]\nA plot of \\(log(-log S(t))\\) against \\(log(t)\\) would give an approximately straight line if the Weibull assumption is reasonable. The plot could also be used to give a rough estimate of the parameters.\nSimilarly, for the log-logistic distribution\n\\[\nlog S(t)/(1 - S(t)) = \\theta - \\kappa log t\n\\]\nFor the log-normal distribution\n\\[\n\\Phi^{-1} (1 - S(t)) = (log t - \\mu) / \\sigma\n\\] The slope and intercept of this line provide estimates of \\(\\sigma^{-1}\\) and \\(-\\mu/\\sigma\\), respectively.\nWe can also check the assumption made with using the Cox regression model of proportional hazards by inspecting the log-cumulative hazard plot.\n\\[\nlog H_i(t) = \\beta x_i + log H_0(t)\n\\]\nThe transformed curves for different values of the explanatory variables will be parallel if PH holds.\nSee Collett (2013) for more details."
  },
  {
    "objectID": "assess-transformed-km.html#r-examples",
    "href": "assess-transformed-km.html#r-examples",
    "title": "Assessing model assumptions using log-cumulative hazard plots",
    "section": "R examples",
    "text": "R examples\nThe package commonly used for survival analyses in R is the survival package (Therneau T 2021). We will begin by repeating an example from the survival help documentation.\nThis uses their reliability data. Firstly a little data manipulation is done before we plot the cumulative hazard plot against time using the in-built survival package plotting method with the cumhaz=TRUE argument.\n\nlibrary(survival)\n\ndata(\"reliability\", package = \"survival\")\n\nvdata <- with(valveSeat, data.frame(id = id, time2 = time, status = status))\nfirst <- !duplicated(vdata$id)\nvdata$time1 <- ifelse(first, 0, c(0, vdata$time[-nrow(vdata)]))\ndouble <- which(vdata$time1 == vdata$time2)\nvdata$time1[double] <- vdata$time1[double] - 0.01\nvdata$time2[double - 1] <- vdata$time1[double]\nvdata[1:7, c(\"id\", \"time1\", \"time2\", \"status\")]\n\n   id  time1  time2 status\n1 251   0.00 761.00      0\n2 252   0.00 759.00      0\n3 327   0.00  98.00      1\n4 327  98.00 667.00      0\n5 328   0.00 326.00      1\n6 328 326.00 652.99      1\n7 328 652.99 653.00      1\n\n\n\nfit <- survfit(Surv(time1, time2, status) ~ 1, data = vdata, id = id)\nplot(fit, cumhaz = TRUE, xlab = \"Days\", ylab = \"Cumulative hazard\")\n\n\n\n\nWe can plot the log-cumulative hazard against log-time by simply plotting the survfit output values directly by specifying the x and y data explicitly.\n\nplot(log(fit$time), log(fit$cumhaz), xlab = \"log-Days\", ylab = \"Log-cumulative hazard\", type = \"l\")\n\n\n\n\nFor the following we will require the latest development version fo the survHE package (Baio 2020). We can obtain this from GitHub with the following.\n\ndevtools::install_github(\"giabaio/survHE\", ref = \"devel\")\n\nNow we can repeat the above analysis using the plot_transformed_km function. By setting distr = \"exp\" the cumulative hazard plot is returned.\n\nfit_exp <- survHE::fit.models(Surv(time1, time2, status) ~ 1,\n                              data = vdata, distr = \"exp\", method = \"mle\")\nsurvHE:::plot_transformed_km(fit_exp)\n\n\n\n\nSetting distr = \"weibull\" then we get the log-cumulative hazard against log-time plot.\n\nfit_wei <- survHE::fit.models(Surv(time1, time2, status) ~ 1,\n                              data = vdata, distr = \"weibull\", method = \"mle\")\nsurvHE:::plot_transformed_km(fit_wei)\n\n\n\n\nThe plot_transformed_km also provides plots for log-normal and log-logistic distribution assumptions with the corresponding transformation to the survival data.\n\n\nplot_transformed_km() function\nplot_transformed_km <- function(fit, mod = 1, add_legend = FALSE,\n                                graph = \"base\", ...) {\n  \n  dots <- list(...)\n  \n  graph <- match.arg(graph, c(\"base\", \"ggplot2\"))\n  \n  if (length(mod) != 1)\n    stop(\"Please provide at most one model index.\")\n  \n  if (is.numeric(mod) && !mod <= length(fit$models))\n    stop(\"More model names provided than available in list of model fits provided.\")\n  \n  if (is.character(mod) && !mod %in% names(fit$models))\n    stop(\"Model name not available in list of model fits provided.\")\n  \n  dist <- get_distribution(fit, mod)\n  \n  distn_names <- list(\n    \"exp\" = c(\"exp\", \"exponential\"),\n    \"weibull\" = c(\"weibull\", \"weibull.quiet\", \"weibullaf\", \"weibullph\"),\n    \"loglogistic\" = c(\"llogis\", \"loglogistic\"),\n    \"lognormal\" = c(\"lognormal\", \"lnorm\"),\n    \"gompertz\" = \"gompertz\")\n  \n  if (!dist %in% unname(unlist(distn_names)))\n    stop(\"Distribution not available.\")\n  \n  fit_km <- fit$misc$km\n  \n  n_strata <- length(fit_km$strata)\n  \n  if (n_strata == 0 || n_strata == 1) {\n    fit_km$strata <- c(\"group\" = length(fit_km$time))\n  }\n  \n  model_strata <- rep(x = names(fit_km$strata),\n                      times = fit_km$strata)\n  \n  times <- split(fit_km$time, model_strata)\n  survs <- split(fit_km$surv, model_strata)\n  \n  params <- list()\n  \n  if (dist %in% distn_names[[\"exp\"]]) {\n    params <- list(\n      FUN = \"lines\",\n      xlab = \"time\",\n      ylab = \"-log(S(t))\",\n      main = \"Exponential distributional assumption\",\n      x = times,\n      y = lapply(survs, function(x) -log(x)),\n      lty = 1:n_strata,\n      col = 1:n_strata,\n      type = \"l\")\n  }\n  \n  if (dist %in% distn_names[[\"weibull\"]]) {\n    params <- list(\n      FUN = \"lines\",\n      xlab = \"log(time)\",\n      ylab = \"log(-log(S(t))) i.e. log cumulative hazard\",\n      main = \"Weibull distributional assumption\",\n      x = lapply(times, log),\n      y = lapply(survs, function(x) log(-log(x))),\n      lty = 1:n_strata,\n      col = 1:n_strata,\n      type = \"l\")\n  }\n  \n  if (dist %in% distn_names[[\"loglogistic\"]]) {\n    params <- list(\n      FUN = \"lines\",\n      xlab = \"time\",\n      ylab = \"log(S(t)/(1-S(t)))\",\n      main = \"log-Logistic distributional assumption\",\n      x = lapply(times, log),\n      y = lapply(survs, function(x) log(x/(1 - x))),\n      lty = 1:n_strata,\n      col = 1:n_strata,\n      type = \"l\")\n  }\n  \n  if (dist %in% distn_names[[\"lognormal\"]]) {\n    params <- list(\n      FUN = \"lines\",\n      xlab = \"log(time)\",\n      ylab = expression(Phi^-1 ~ (1 - S(t))),\n      main = \"Log-normal distributional assumption\",\n      x = lapply(times, log),\n      y = lapply(survs, function(x) qnorm(1 - x)),\n      lty = 1:n_strata,\n      col = 1:n_strata,\n      type = \"l\")\n  }\n  \n  default_pars <- list(\n    x = NULL,\n    type = \"n\",\n    axes = FALSE,\n    xlab = params$xlab,\n    ylab = params$ylab,\n    main = params$main,\n    xlim = range(pretty(unlist(params$x))),\n    ylim = range(pretty(unlist(params$y))))\n  \n  setup_pars <- modifyList(\n    default_pars, dots[names(default_pars)])\n  \n  if (graph == \"base\") {\n    \n    # empty plot\n    do.call(plot, setup_pars)\n    \n    axis(1); axis(2)\n    \n    # plot lines\n    do.call(mapply, modifyList(params, dots))\n    \n    if (isTRUE(add_legend)) {\n      legend(\"topright\", names(survs), col = params$col,\n             lty = params$lty, bty = \"n\")\n    }\n  }\n  \n  if (graph == \"ggplot2\") {\n    \n    if (!add_legend) {\n      pos.legend <- \"none\"\n    } else {\n      pos.legend <- \"right\"}\n    \n    ggdata <- \n      data.frame(time = unlist(params$x),\n                 y = unlist(params$y)) |>\n      tibble::rownames_to_column(\"Group\") |> \n      mutate(Group = gsub(\"\\\\d+\", \"\", Group))\n    \n    p <- \n      ggplot(ggdata, aes(x = .data$time, y = .data$y,\n                         group = .data$Group, col = .data$Group)) +\n      geom_line() +\n      do.call(labs,\n              list(title = setup_pars$main,\n                   x = setup_pars$xlab,\n                   y = setup_pars$ylab)) +\n      theme_bw() +\n      theme(legend.position = pos.legend)\n    \n    print(p)\n  }\n  \n  invisible(params)\n}\n\n\nFurther, we could use the flexsurv package (Jackson 2016). This package contains lots of functions for a range of survival distributions.\nThe cumulative hazard can be plotted with the flexsurv plotting method with argument type = \"cumhaz\". The Kaplan-Meier is also overlaid by the model fit.\n\nlibrary(\"flexsurv\")\n\nfs1 <- flexsurvreg(Surv(time1, time2, status) ~ 1, data = vdata, dist = \"exp\")\nplot(fs1, type = \"cumhaz\")\n\n\n\nfs2 <- flexsurvreg(Surv(time1, time2, status) ~ 1, data = vdata, dist = \"weibull\")\nplot(fs2, type = \"cumhaz\")"
  },
  {
    "objectID": "basic-visual-inspection.html",
    "href": "basic-visual-inspection.html",
    "title": "Basic visual inspection",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blended-curves.html",
    "href": "blended-curves.html",
    "title": "Blended curves",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "external-data.html",
    "href": "external-data.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "surv-extrapolation",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro-to-R.html",
    "href": "intro-to-R.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Log-cumulative-hazard-plot.html",
    "href": "Log-cumulative-hazard-plot.html",
    "title": "Log Cumulative Hazard Plot",
    "section": "",
    "text": "library(survival)\n\ndata(\"reliability\", package = \"survival\")\n\nvdata <- with(valveSeat, data.frame(id=id, time2=time, status=status))\nfirst <- !duplicated(vdata$id)\nvdata$time1 <- ifelse(first, 0, c(0, vdata$time[-nrow(vdata)]))\ndouble <- which(vdata$time1 == vdata$time2)\nvdata$time1[double] <- vdata$time1[double] -.01\nvdata$time2[double-1] <- vdata$time1[double]\nvdata[1:7, c(\"id\", \"time1\", \"time2\", \"status\")]\n\n   id  time1  time2 status\n1 251   0.00 761.00      0\n2 252   0.00 759.00      0\n3 327   0.00  98.00      1\n4 327  98.00 667.00      0\n5 328   0.00 326.00      1\n6 328 326.00 652.99      1\n7 328 652.99 653.00      1\n\nvfit <- survfit(Surv(time1, time2, status) ~1, data=vdata, id=id)\nplot(vfit, cumhaz=TRUE, xlab=\"Days\", ylab=\"Cumulative hazard\")\n\n\n\n\nflexsurv package\n\nHexp(x, rate = 1, log = FALSE)\nHgamma(x, shape, rate = 1, log = FALSE)\nHlnorm(x, meanlog = 0, sdlog = 1, log = FALSE)\nHweibull(x, shape, scale = 1, log = FALSE)\n\n\nlibrary(\"flexsurv\")\nfs1 <- flexsurvreg(Surv(recyrs, censrec) ~ group, data = bc, dist = \"weibull\")\nplot(fs1, type = \"cumhaz\")\n\n\n\n\nmuhaz package\nsurvHE::test.linear.assumptions"
  },
  {
    "objectID": "other-hybrid-methods.html",
    "href": "other-hybrid-methods.html",
    "title": "Other hybrid methods",
    "section": "",
    "text": "References\n\nGelber, Richard D., Aron Goldhirsch, and Bernard F. Cole. 1993. “Parametric extrapolation of survival estimates with applications to quality of life evaluation of treatments.” Control. Clin. Trials 14 (6): 485–99. https://doi.org/10.1016/0197-2456(93)90029-D."
  },
  {
    "objectID": "other-methods.html",
    "href": "other-methods.html",
    "title": "Other methods",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "parametric-modelling.html",
    "href": "parametric-modelling.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "PH-modelling.html",
    "href": "PH-modelling.html",
    "title": "Proportional Hazard Modelling",
    "section": "",
    "text": "Goeman, J., Meijer, R. and Chaturvedi, N. (2013) L 1 (lasso and fused lasso) and L 2 (ridge) penalized estimation in GLMs and in the Cox model. R package version 0.9-42"
  },
  {
    "objectID": "restricted-means.html",
    "href": "restricted-means.html",
    "title": "Restricted Means",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  }
]